## Discussion & Reflection —  Coding Best Practices

There is no article for this week, just the below summary. 

Good coding practices make your work easier to understand, more reproducible, and more collaborative. The principles generalize across all types of programming.

### Why these practices

- **Readers first:** Your future self and collaborators should understand decisions and reproduce results without guessing.
- **Science first:** Transparent workflows reduce errors and make findings more trustworthy.

---

### Readability and Clarity

- Use **descriptive names** for objects and functions (`bee_abundance`, not `ba1`).
- Chose a style for objects vs. functions, for example `bee_abundance` for an object and `calcBeeAbundance` for a function. 
- Function names should be verbs. 
- Keep lines and functions **short**; prefer many small steps over one cryptic line.
- Write **comments** that explain the *why*, not only the *what*.
- Follow a consistent **style** (indentation, spacing, brace placement). In R, consider `styler` and the tidyverse style guide.
- Prefer **explicit** over clever: clarity beats concision.

**Example**

```
# Good
daily_mean <- dplyr::summarise(weather,
                               mean_temp = mean(temp_c, na.rm = TRUE))

# Avoid
dm <- summarise(w, m = mean(t, TRUE))
```

---

### Reproducibility

- Use **relative paths** (e.g., `data/flowers.csv`) and project roots (e.g., `here::here("data", "flowers.csv")`).
- Record package versions when publishing (`sessionInfo()`, `renv`, or `pak`).
- Set seeds for stochastic steps: `set.seed(2025)`.
- Save outputs **via code** (figures, tables) so they can be re-generated. This is in contrast to exporting a figure from Rstudio by hand. Use `ggsave` to export the plot to a file within your script. Similarly, you can export a table as a csv (`write.csv`) or to latex format if you use latex.

**Example**

```r
# Reproducible file paths
library(here)
raw <- read.csv(here::here("data", "flowers.csv"))
write.csv(raw, here::here("outputs", "flowers_clean.csv"), row.names = FALSE)
```

---

### Modularity and Reuse

- Break large scripts into **functions** and small files with clear responsibilities.
- Keep **raw data immutable**; write code that creates derived data.
- Structure projects predictably (e.g., RStudio Project + folders: `data-raw/`, `data/`, `scripts/`, `figs/`, `doc/`, `outputs/`).

**Example**

```r
# R/clean_flower_data.R
clean_flower_data <- function(df) {
  df %>%
    dplyr::filter(!is.na(species)) |>
    dplyr::mutate(date = as.Date(date))
}
```

---

### Documentation

- Provide a **README** with purpose, data sources, how to run, and expected outputs.
- Add **data dictionaries** (variable names, units, provenance, licenses).
- Document functions with **roxygen2** (inputs, outputs, side effects, examples).
- Prefer **literate programming** (R Markdown / Quarto) for analyses that combine text, code, and results.

**Checklist for README**

- Project goal, authors, contact
- Folder map and what belongs where
- Data sources & licenses
- Reproduction steps (scripts/targets)
- Software versions / environment

---


### Testing and Validation

- Test critical functions with **unit tests** (`testthat`), and edge cases (NA, empty, extreme values).
- Run analyses in a **clean session** to catch hidden dependencies.

**Example**

```r
# tests/test-clean_flower_data.R
test_that("dates are parsed", {
  df <- data.frame(species = "a", date = "2024-01-01")
  out <- clean_flower_data(df)
  expect_true(inherits(out$date, "Date"))
})
```

---

### Efficiency (after correctness and clarity)

- Optimize for **clarity first**; profile later if needed to increase efficiency if running something that takes a while (`profvis`, `bench`).
- Prefer **vectorized** operations and database-backed workflows for large data.
- Cache expensive steps (e.g., using `targets` or `drake`) or output .Rdata files to avoid unnecessary recomputation.

---

### Quick Checklist

- [ ] Clear names & consistent style  
- [ ] Small, focused functions  
- [ ] Immutable *raw* data; scripted transformations  
- [ ] Relative paths & project root (`here`)  
- [ ] Random seeds set; session info recorded  
- [ ] README + data dictionary present  
- [ ] Version control with meaningful commits  
- [ ] Unit tests for critical functions  
- [ ] Plots/tables generated by code (not hand-edited)  

---

#### Pre‑class reflection (please submit short answers via canvas)

- Clarity first. Find one code chunk from your own recent work (e.g., last week or this week's lab, other work) that is hard to read. Rewrite it with clearer names and comments. In 2–3 sentences, explain what you changed and why.

- Reproducibility gaps. List three things that would prevent a stranger from fully reproducing your latest analysis. For each, write a one-line fix.

- Data hygiene. Describe how you differentiate raw vs. derived data in your final project or other research project you are working on. If you don’t yet, sketch the folder structure and file-naming convention you will adopt.

- Testing mindset. Pick one function or code block you rely on. Write two quick tests or checks you could implement (edge case + typical case).

- Figures to outputs. Choose a figure you made recently. Write the code you would use to export it to a pdf, including the exact relative paths. Paste the code below (it does need to run)

```r
```

#### In‑class small‑group prompts

**1. Style & standards** Draft a one-page team style guide:

- Object/column naming rules
- Commenting conventions (where and why)
- File/figure naming (encode date/seed/version?)
- How to handle random seeds and session info

**2. Guidelines** What of the above guidelines would people like to discuss more? Are there guidelines that are confusing or unclear?

